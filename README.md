# ğŸ–¼ï¸ Mixture-of-Experts Image Captioner  

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-App-red?logo=streamlit)
![Docker](https://img.shields.io/badge/Docker-ready-blue?logo=docker)
![License](https://img.shields.io/badge/license-MIT-green)

This repository provides a **Mixture-of-Experts (MoE)** system for **image captioning** that combines:  

ğŸ”¹ **Vision Expert (ResNet-50)** for object and color recognition  
ğŸ”¹ **Gating Network** to decide whether to use a lightweight template or a full language model  
ğŸ”¹ **Ollama LLM (e.g., llama3)** for natural, detailed captions  

The goal is to generate **concise, vivid, and grounded captions** for uploaded images while balancing **speed, interpretability, and richness**.

---

## âœ¨ Features

âœ… **Hybrid routing**: Gating selects between:
- **Template captions** (fast, grounded in top labels and colors)  
- **LLM-generated captions** (richer, more descriptive)  

âœ… **Vision expert**: ResNet-50 trained on ImageNet with color + complexity analysis  
âœ… **Configurable thresholds**: Confidence and entropy bounds for gating  
âœ… **Local LLM support**: Integration with [Ollama](https://ollama.com) for running llama3 or other models  
âœ… **Streamlit UI** for interactive testing  
âœ… **CLI tool** for batch or scripted usage  
âœ… **Docker support** for containerized deployment  

---

## ğŸ›  Project Structure

```
.
â”œâ”€ app.py                 # Streamlit web app
â”œâ”€ basic_caption.py        # CLI tool for caption generation
â”œâ”€ moe/
â”‚  â”œâ”€ describer.py         # MoEImageDescriber logic
â”‚  â”œâ”€ gate.py              # Gating network (template vs LLM)
â”‚  â”œâ”€ classifier.py        # Vision classifier (ResNet-50 + color analysis)
â”‚  â”œâ”€ ollama_client.py     # Client for Ollama LLM
â”‚  â”œâ”€ templates.py         # Prompt templates
â”‚  â”œâ”€ few_shot.py          # (Optional) few-shot support
â”‚  â””â”€ ...
â”œâ”€ Dockerfile              # Build + run container
â”œâ”€ model_config.yaml       # Model + device configuration
â”œâ”€ prompt_templates.yaml   # Prompt formats
â”œâ”€ logging_config.yaml     # Logging setup
â””â”€ notebooks/              # Experiments and analysis
```

---

## ğŸš€ Usage

### â–¶ï¸ Run locally (Streamlit UI)
```bash
pip install -r requirements.txt
streamlit run app.py
```

Then open [http://localhost:8501](http://localhost:8501).

### ğŸ’» Run CLI
```bash
python basic_caption.py --image sample.jpg --device cpu
```

### ğŸ³ Run with Docker
```bash
docker build -t moe-captioner .
docker run -p 8501:8501 moe-captioner
```

---

## âš™ï¸ Configuration

âš¡ **`model_config.yaml`**: select device (cpu/cuda), model paths, etc.  
âš¡ **`prompt_templates.yaml`**: define caption prompts for LLM.  
âš¡ **`logging_config.yaml`**: adjust logging level/format.  
âš¡ **Thresholds** (`confidence`, `entropy`) control when the gate chooses template vs LLM.  

---

## ğŸ“Œ Example

Upload an image â†’ system classifies objects/colors â†’ gate decides:  
- If **simple + high confidence** â†’ template caption (e.g., â€œA photo of a dog with brown tones.â€)  
- If **complex/uncertain** â†’ llama3 generates natural caption.  

---

## ğŸ“¸ Screenshots

_Add screenshots of the Streamlit UI here._

---

## ğŸ“œ License
Licensed under the **MIT License**. See `LICENSE` for details.
